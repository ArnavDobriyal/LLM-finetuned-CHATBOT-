import pandas as pd
from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments


def load_dataset(file_path, tokenizer, block_size=128):
    # Read data from CSV file into a DataFrame
    df = pd.read_csv(file_path)

    # Extract user inputs and prompts from the DataFrame
    prompts = df['user_input'].tolist()
    user_inputs = df['prompt'].tolist()

    # Combine user inputs and prompts to create training texts
    texts = [f"User: {user_input} Therapist: {prompt}" for user_input, prompt in zip(user_inputs, prompts)]

    # Save the training texts to a file
    with open('train_dataset.txt', 'w') as f:
        for text in texts:
            f.write(text + '\n')

    # Create a TextDataset from the training file
    dataset = TextDataset(
        tokenizer=tokenizer,
        file_path='train_dataset.txt',
        block_size=block_size,
    )
    return dataset

# Define a function to load the data collator for training
def load_data_collator(tokenizer, mlm=False):
    # Create a DataCollatorForLanguageModeling instance
    data_collator = DataCollatorForLanguageModeling(
        tokenizer=tokenizer,
        mlm=mlm,
    )
    return data_collator

# Define a function to train the therapist model
def train_therapist_model(train_file_path, output_dir):
    # Set the model name
    model_name = "gpt2-medium"

    # Create a GPT2Tokenizer instance
    tokenizer = GPT2Tokenizer.from_pretrained(model_name)

    # Load the training dataset
    train_dataset = load_dataset(train_file_path, tokenizer)

    # Load the data collator for training
    data_collator = load_data_collator(tokenizer)

    # Save the tokenizer's vocabulary to the output directory
    tokenizer.save_pretrained(output_dir)

    # Load the GPT-2 model
    model = GPT2LMHeadModel.from_pretrained(model_name)

    # Save the GPT-2 model to the output directory
    model.save_pretrained(output_dir)

    # Define training arguments
    training_args = TrainingArguments(
        output_dir=output_dir,
        overwrite_output_dir=True,
        per_device_train_batch_size=4,
        num_train_epochs=50,
        save_steps=10_000,
    )

    # Create a Trainer instance
    trainer = Trainer(
        model=model,
        args=training_args,
        data_collator=data_collator,
        train_dataset=train_dataset,
    )

    # Train the model
    trainer.train()

# Call the function to train the therapist model
# Specify the path to the training file and the output directory for the model
train_therapist_model("path/to/train_dataset.csv", "output_model")
trainer.save_model()
